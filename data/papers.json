[
  {
    "title": "GigaBrain-0: A World Model-Powered Vision-Language-Action Model",
    "category": "Semantic Reasoning",
    "summary": "GigaBrain-0 is a VLA foundation model that utilizes world-model-generated data and embodied Chain-of-Thought supervision to achieve superior generalization and long-horizon reasoning for complex robotic tasks.",
    "key_concepts": [
      "Embodied Chain-of-Thought (CoT)",
      "World Model-Generated Data",
      "RGBD Input Modeling",
      "Long-horizon Planning",
      "Generalist Robots"
    ],
    "filename": "GigaBrain-0 A World Model-Powered Vision-Language-Action Model.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Semantic Reasoning/GigaBrain-0 A World Model-Powered Vision-Language-Action Model.pdf"
  },
  {
    "title": "FASTER: TOWARD EFFICIENT AUTOREGRESSIVE VISION LANGUAGE ACTION MODELING VIA NEURAL ACTION TOKENIZATION",
    "category": "Speed and Deployment",
    "summary": "This paper introduces FASTer, a framework that improves the inference speed and efficiency of autoregressive Vision-Language-Action (VLA) models through a learnable action tokenizer and block-wise autoregressive decoding.",
    "key_concepts": [
      "neural action tokenization",
      "block-wise autoregression",
      "inference efficiency"
    ],
    "filename": "FASTer Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Speed and Deployment/FASTer Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization.pdf"
  },
  {
    "title": "GigaBrain-0: A World Model-Powered Vision-Language-Action Model",
    "category": "Robustness and Reliability",
    "summary": "This paper introduces a VLA foundation model that utilizes world model-generated data\u2014including Real2Real and view transfers\u2014to overcome real-world data scarcity and enhance policy robustness across diverse environments.",
    "key_concepts": [
      "World Models",
      "Sim2Real Transfer",
      "Real2Real Transfer",
      "Embodied Chain-of-Thought",
      "RGBD Input Modeling"
    ],
    "filename": "GigaBrain-0 A World Model-Powered Vision-Language-Action Model.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Robustness and Reliability/GigaBrain-0 A World Model-Powered Vision-Language-Action Model.pdf"
  },
  {
    "title": "Real-Time Execution of Action Chunking Flow Policies",
    "category": "Speed and Deployment",
    "summary": "The paper introduces Real-Time Chunking (RTC), an inference-time algorithm that enables smooth, asynchronous execution of high-latency action chunking policies by treating the generation of subsequent chunks as an inpainting problem.",
    "key_concepts": [
      "action chunking",
      "inference latency",
      "asynchronous execution",
      "flow matching inpainting",
      "real-time control"
    ],
    "filename": "Real-Time Execution of Action Chunking Flow Policies.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Speed and Deployment/Real-Time Execution of Action Chunking Flow Policies.pdf"
  },
  {
    "title": "VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference",
    "category": "Speed and Deployment",
    "summary": "VLASH is a general asynchronous inference framework for Vision-Language-Action models that eliminates action stalls and reduces reaction latency by conditioning predictions on estimated future robot states through state roll-forward and temporal-offset fine-tuning.",
    "key_concepts": [
      "Asynchronous Inference",
      "Future-State-Awareness",
      "Temporal Misalignment",
      "State Roll-forward",
      "Action Quantization",
      "Temporal-Offset Augmentation"
    ],
    "filename": "VLASH Real-Time VLAs via Future-State-Aware Asynchronous Inference.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Speed and Deployment/VLASH Real-Time VLAs via Future-State-Aware Asynchronous Inference.pdf"
  },
  {
    "title": "SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models",
    "category": "Algorithmic Foundations",
    "summary": "SRPO introduces a self-referential reinforcement learning framework for VLA models that mitigates reward sparsity by using in-batch successful trajectories and latent world representations to provide dense, progress-wise rewards for failed attempts.",
    "key_concepts": [
      "Self-Referential Policy Optimization",
      "Vision-Language-Action (VLA) Models",
      "Latent World Representations",
      "Progress-wise Reward Modeling",
      "Reinforcement Learning Post-training"
    ],
    "filename": "SRPO Self-Referential Policy Optimization for Vision-Language-Action Models.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Algorithmic Foundations/SRPO Self-Referential Policy Optimization for Vision-Language-Action Models.pdf"
  },
  {
    "title": "DEAS: DETACHED VALUE LEARNING WITH ACTION SEQUENCE FOR SCALABLE OFFLINE RL",
    "category": "Systems and Scale | Algorithmic Foundations",
    "summary": "DEAS is an offline RL framework that leverages action sequences within an options framework and employs detached value learning to improve performance and stability on complex, long-horizon manipulation tasks.",
    "key_concepts": [
      "Action Sequences",
      "Detached Value Learning",
      "Offline Reinforcement Learning",
      "Options Framework (SMDP)",
      "Vision-Language-Action Models (VLAs)"
    ],
    "filename": "DEAS DEtached value learning with Action Sequence for Scalable Offline RL.pdf",
    "github_link": "https://github.com/ai-sales-agent-25/VLA-RL-Papers/blob/main/papers/Systems and Scale | Algorithmic Foundations/DEAS DEtached value learning with Action Sequence for Scalable Offline RL.pdf"
  }
]